{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4042ba1",
   "metadata": {},
   "source": [
    "Logistic Regression on breast cancer dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "12afb987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (569, 30), y shape: (569,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "b460407b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0: 212\n",
      "class 1: 357\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y, return_counts=True)\n",
    "for cls, cnt in zip(unique, counts):\n",
    "    print(f\"class {cls}: {cnt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f5fe05",
   "metadata": {},
   "source": [
    "Slight imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "dfd13a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pre, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=6)\n",
    "X_val_pre, X_test_pre, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=6)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_pre)\n",
    "X_val = scaler.fit_transform(X_val_pre)\n",
    "X_test = scaler.fit_transform(X_test_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5d1b8a",
   "metadata": {},
   "source": [
    "![Gradients](figures/paperwork.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd90439",
   "metadata": {},
   "source": [
    "With the L2 regularization, I switched to dividing by 2, instead of 2m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "b1634ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.random((1, X.shape[1]))\n",
    "b = np.random.random(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "cfe98b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "b64fa0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 train loss: 0.8425136817315212, validation loss: 0.9479056436095008\n",
      "Epoch 20 train loss: 0.3590239509140598, validation loss: 0.4529945997112484\n",
      "Epoch 30 train loss: 0.2890649968787759, validation loss: 0.3708312255660373\n",
      "Epoch 40 train loss: 0.26157479261184774, validation loss: 0.33996885768294854\n",
      "Epoch 50 train loss: 0.24471527327670523, validation loss: 0.3225622870415416\n",
      "Epoch 60 train loss: 0.23257965392465862, validation loss: 0.3107879909496402\n",
      "Epoch 70 train loss: 0.2233248421447084, validation loss: 0.30215451404430765\n",
      "Epoch 80 train loss: 0.2160952484527097, validation loss: 0.29556773039790557\n",
      "Epoch 90 train loss: 0.21038085447968186, validation loss: 0.29042943756850703\n",
      "Epoch 100 train loss: 0.20583353480363667, validation loss: 0.28636360880976786\n",
      "Epoch 110 train loss: 0.2021989925826744, validation loss: 0.283113115479323\n",
      "Epoch 120 train loss: 0.1992848905498313, validation loss: 0.28049299832338614\n",
      "Epoch 130 train loss: 0.19694288270417482, validation loss: 0.27836593662875286\n",
      "Epoch 140 train loss: 0.19505714771581587, validation loss: 0.2766278306794681\n",
      "Epoch 150 train loss: 0.19353650227082034, validation loss: 0.2751986130602562\n",
      "Epoch 160 train loss: 0.1923087257058672, validation loss: 0.27401604887815717\n",
      "Epoch 170 train loss: 0.19131635599332167, validation loss: 0.27303137932297866\n",
      "Epoch 180 train loss: 0.1905135129942255, validation loss: 0.27220616830303895\n",
      "Epoch 190 train loss: 0.18986346282865804, validation loss: 0.2715099685333061\n",
      "Epoch 200 train loss: 0.18933672977874288, validation loss: 0.2709185644322236\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "lambda_ = 0.1\n",
    "bs = 4\n",
    "lr = 0.001\n",
    "eps = 1e-12\n",
    "M = X_train.shape[0]\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    c = 0\n",
    "    for i in range(int(np.ceil(M / bs))):\n",
    "        x, y = X_train[c:c+bs], y_train[c:c+bs].reshape(-1, 1)\n",
    "        m = x.shape[0]\n",
    "        p = sigmoid(x @ w.T + b)\n",
    "        p = np.clip(p, eps, 1-eps)\n",
    "        loss = np.sum(-y * np.log(p) - (1-y) * np.log(1 - p)) / m + (lambda_ / (2)) * np.sum(w**2)\n",
    "        d_w = (((p - y).T @ x) / m) + lambda_ * w\n",
    "        d_b = np.mean(p - y)\n",
    "\n",
    "        w -= lr * d_w\n",
    "        b -= lr * d_b\n",
    "\n",
    "        total_loss += loss\n",
    "        c += bs\n",
    "    \n",
    "    val_p = sigmoid(X_val @ w.T + b).flatten()\n",
    "    val_p = np.clip(val_p, eps, 1-eps)\n",
    "    val_loss = np.mean(-y_val * np.log(val_p) - (1-y_val) * np.log(1 - val_p)) + (lambda_ / 2) * np.sum(w**2)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1} train loss: {total_loss / int(np.ceil(M / bs))}, validation loss: {val_loss}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6494c304",
   "metadata": {},
   "source": [
    "0 = malignant, 1 = benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "f10f6065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen threshold: 0.901\n"
     ]
    }
   ],
   "source": [
    "val_p = sigmoid(X_val @ w.T + b).flatten()\n",
    "\n",
    "target_recall = 1.0\n",
    "best_t = None\n",
    "\n",
    "for t in np.linspace(0, 1, 1001):\n",
    "    y_pred = (val_p > t).astype(int)\n",
    "\n",
    "    tp = np.sum((y_val == 0) & (y_pred == 0))\n",
    "    fn = np.sum((y_val == 0) & (y_pred == 1))\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "    if recall >= target_recall:\n",
    "        best_t = t\n",
    "        break\n",
    "\n",
    "print(\"Chosen threshold:\", best_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac1edd5",
   "metadata": {},
   "source": [
    "Round down to 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "dd6756f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.996606334841629\n",
      "Recall score: 1.0\n",
      "Precision score: 0.85\n",
      "False Negatives: 0\n",
      "False Positives: 6\n"
     ]
    }
   ],
   "source": [
    "test_p = sigmoid(X_test @ w.T + b).flatten()\n",
    "y_pred = (test_p > 0.90).astype(int) # If p(benign) > 0.90 predict benign\n",
    "\n",
    "tp = np.sum((y_test == 0) & (y_pred == 0))\n",
    "fn = np.sum((y_test == 0) & (y_pred == 1))\n",
    "fp = np.sum((y_test == 1) & (y_pred == 0))\n",
    "recall = tp / (tp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(f\"ROC AUC score: {roc_auc_score(y_test, test_p)}\")\n",
    "print(f\"Recall score: {recall}\")\n",
    "print(f\"Precision score: {precision}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"False Positives: {fp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db0b497",
   "metadata": {},
   "source": [
    "While these results are good, they are evaluated on a small test set. Recall is perfect on this test split, meaning no malignant tumors are missed. Precision is lower at 0.85, 6 benign cases were incorrectly flagged as malignant. This is intentional, this model prioritizes as little false negatives as possible at the cost of a small number of false positives which is acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "ef0eb4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.9660633484162896\n",
      "Recall score: 0.9705882352941176\n",
      "Precision score: 0.9428571428571428\n",
      "False Negatives: 1\n",
      "False Positives: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rowes\\Documents\\GitHub\\2026-ML-Projects\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, recall_score, precision_score, confusion_matrix\n",
    "\n",
    "model = LogisticRegression(penalty='l2')\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "p = model.predict_proba(X_test)[:, 1]\n",
    "t = 0.9\n",
    "y_pred = (p > t).astype(int)\n",
    "\n",
    "recall = recall_score(y_test, y_pred, pos_label=0)\n",
    "precision = precision_score(y_test, y_pred, pos_label=0)\n",
    "roc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "fn = cm[0, 1]\n",
    "fp = cm[1, 0]\n",
    "\n",
    "print(f\"ROC AUC score: {roc}\")\n",
    "print(f\"Recall score: {recall}\")\n",
    "print(f\"Precision score: {precision}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"False Positives: {fp}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
