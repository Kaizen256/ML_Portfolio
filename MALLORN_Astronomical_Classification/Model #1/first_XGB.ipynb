{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0d25455",
   "metadata": {},
   "source": [
    "# Model 1 (Baseline XGBoost)\n",
    "\n",
    "First attempt at building a model for this competition.\n",
    "\n",
    "### What this model does\n",
    "- Uses basic lightcurve-derived statistical features\n",
    "- Trains an XGBoost binary classifier\n",
    "- Uses Optuna to tune hyperparameters for F1\n",
    "- Tunes a custom probability threshold to maximize validation F1\n",
    "- Generates Kaggle submissions (I submitted twice using different seeds)\n",
    "\n",
    "## Results\n",
    "\n",
    "Best parameters:\n",
    "- n_estimators: 1556\n",
    "- learning_rate: 0.011529\n",
    "- max_depth: 5\n",
    "- min_child_weight: 11\n",
    "- subsample: 0.990469\n",
    "- colsample_bytree: 0.964860\n",
    "- colsample_bylevel: 0.931161\n",
    "- gamma: 0.008020\n",
    "- reg_alpha: 7.434848\n",
    "- reg_lambda: 1.937161\n",
    "\n",
    "OOF multiseed best threshold: 0.5147491638795987  \n",
    "Best validation F1: 0.730769  \n",
    "\n",
    "| Submission | Public LB F1 | Private LB F1 |\n",
    "|-------------|--------------|----------------|\n",
    "| 1 | 0.4582 | 0.4153 |\n",
    "| 2 | 0.4610 | 0.4540 |\n",
    "\n",
    "\n",
    "This model did not use heavy feature engineering, and mainly focuses on extracting simple per-object + per-filter summary stats from the raw lightcurve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81e22f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd().parents[0]\n",
    "DATA_DIR = ROOT / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2038e69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>Z</th>\n",
       "      <th>Z_err</th>\n",
       "      <th>EBV</th>\n",
       "      <th>SpecType</th>\n",
       "      <th>English Translation</th>\n",
       "      <th>split</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dornhoth_fervain_onodrim</td>\n",
       "      <td>3.0490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.110</td>\n",
       "      <td>AGN</td>\n",
       "      <td>Trawn Folk (Dwarfs) + northern + Ents (people)</td>\n",
       "      <td>split_01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dornhoth_galadh_ylf</td>\n",
       "      <td>0.4324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.058</td>\n",
       "      <td>SN II</td>\n",
       "      <td>Trawn Folk (Dwarfs) + tree + drinking vessel</td>\n",
       "      <td>split_01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elrim_melethril_thul</td>\n",
       "      <td>0.4673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.577</td>\n",
       "      <td>AGN</td>\n",
       "      <td>Elves +  lover (fem.)  + breath</td>\n",
       "      <td>split_01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ithil_tobas_rodwen</td>\n",
       "      <td>0.6946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012</td>\n",
       "      <td>AGN</td>\n",
       "      <td>moon +  roof  +  noble maiden</td>\n",
       "      <td>split_01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mirion_adar_Druadan</td>\n",
       "      <td>0.4161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.058</td>\n",
       "      <td>AGN</td>\n",
       "      <td>jewel, Silmaril  + father + Wild Man</td>\n",
       "      <td>split_01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3038</th>\n",
       "      <td>tinnu_gellui_tathar</td>\n",
       "      <td>0.8898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042</td>\n",
       "      <td>AGN</td>\n",
       "      <td>dusk, twilight + triumphant + tathar</td>\n",
       "      <td>split_20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3039</th>\n",
       "      <td>uir_heleg_corf</td>\n",
       "      <td>0.9598</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042</td>\n",
       "      <td>AGN</td>\n",
       "      <td>eternity + ice + ring</td>\n",
       "      <td>split_20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3040</th>\n",
       "      <td>uir_rhosc_law</td>\n",
       "      <td>0.1543</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024</td>\n",
       "      <td>SN II</td>\n",
       "      <td>eternity +  russet, red, brown + no! don't!</td>\n",
       "      <td>split_20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3041</th>\n",
       "      <td>uruk_in_pess</td>\n",
       "      <td>1.1520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019</td>\n",
       "      <td>AGN</td>\n",
       "      <td>evil creature + year + feather</td>\n",
       "      <td>split_20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042</th>\n",
       "      <td>ylf_alph_mindon</td>\n",
       "      <td>0.5595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034</td>\n",
       "      <td>SN Ia-91T-like</td>\n",
       "      <td>drinking vessel  + swan + isolated hill</td>\n",
       "      <td>split_20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3043 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     object_id       Z  Z_err    EBV        SpecType  \\\n",
       "0     Dornhoth_fervain_onodrim  3.0490    NaN  0.110             AGN   \n",
       "1          Dornhoth_galadh_ylf  0.4324    NaN  0.058           SN II   \n",
       "2         Elrim_melethril_thul  0.4673    NaN  0.577             AGN   \n",
       "3           Ithil_tobas_rodwen  0.6946    NaN  0.012             AGN   \n",
       "4          Mirion_adar_Druadan  0.4161    NaN  0.058             AGN   \n",
       "...                        ...     ...    ...    ...             ...   \n",
       "3038       tinnu_gellui_tathar  0.8898    NaN  0.042             AGN   \n",
       "3039            uir_heleg_corf  0.9598    NaN  0.042             AGN   \n",
       "3040             uir_rhosc_law  0.1543    NaN  0.024           SN II   \n",
       "3041              uruk_in_pess  1.1520    NaN  0.019             AGN   \n",
       "3042           ylf_alph_mindon  0.5595    NaN  0.034  SN Ia-91T-like   \n",
       "\n",
       "                                  English Translation     split  target  \n",
       "0     Trawn Folk (Dwarfs) + northern + Ents (people)   split_01       0  \n",
       "1       Trawn Folk (Dwarfs) + tree + drinking vessel   split_01       0  \n",
       "2                     Elves +  lover (fem.)  + breath  split_01       0  \n",
       "3                       moon +  roof  +  noble maiden  split_01       0  \n",
       "4               jewel, Silmaril  + father + Wild Man   split_01       0  \n",
       "...                                               ...       ...     ...  \n",
       "3038             dusk, twilight + triumphant + tathar  split_20       0  \n",
       "3039                            eternity + ice + ring  split_20       0  \n",
       "3040     eternity +  russet, red, brown + no! don't!   split_20       0  \n",
       "3041                   evil creature + year + feather  split_20       0  \n",
       "3042         drinking vessel  + swan + isolated hill   split_20       0  \n",
       "\n",
       "[3043 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_DIR / \"train_log.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12c71825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object_id                 0\n",
       "Z                         0\n",
       "Z_err                  3043\n",
       "EBV                       0\n",
       "SpecType                  0\n",
       "English Translation       0\n",
       "split                     0\n",
       "target                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9252f6ce",
   "metadata": {},
   "source": [
    "## Dropping columns\n",
    "\n",
    "Before feature building, I removed columns that are not useful for this baseline model. I didn't know what to do with SpecType at the time so i removed it, a Kaggle user later pointed out in a discussion that there is a very good way to use SpecType. Z_err was also not used yet. Z_err is only null for the training values. This is also one of the reasons the model didn't perform too well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa66ff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Z_err', 'English Translation', 'SpecType'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f011bf94",
   "metadata": {},
   "source": [
    "## Loading lightcurve files\n",
    "\n",
    "The dataset is stored in separate folders by `split`.\n",
    "\n",
    "Instead of re-reading CSV files every time I want an object's lightcurve, I load each split's full lightcurve file once and store it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1b9d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = 20\n",
    "light_curve_cache = {}\n",
    "idx_cache = {}\n",
    "\n",
    "for s in df['split'].unique():\n",
    "    path = DATA_DIR / str(s) / f\"train_full_lightcurves.csv\"\n",
    "    light_curve = pd.read_csv(path)\n",
    "\n",
    "    groups = light_curve.groupby(\"object_id\").indices\n",
    "\n",
    "    light_curve_cache[s] = light_curve\n",
    "    idx_cache[s] = groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a294b1b",
   "metadata": {},
   "source": [
    "## get_lightcurve(split, object_id)\n",
    "\n",
    "This function retrieves the full lightcurve rows for a single object.\n",
    "\n",
    "Inputs:\n",
    "- split: which data split folder the object belongs to\n",
    "- object_id: unique object identifier\n",
    "\n",
    "Steps:\n",
    "- Look up the row indices for that object in idx_cache\n",
    "- Use .iloc[idx] to extract the object's rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0c4cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lightcurve(split, object_id):\n",
    "    df = light_curve_cache[split]\n",
    "    idx = idx_cache[split].get(object_id)\n",
    "    return df.iloc[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8155d883",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "85f5ab7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>Time (MJD)</th>\n",
       "      <th>Flux</th>\n",
       "      <th>Flux_err</th>\n",
       "      <th>Filter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>Ithil_tobas_rodwen</td>\n",
       "      <td>62867.5631</td>\n",
       "      <td>0.462736</td>\n",
       "      <td>1.159424</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>Ithil_tobas_rodwen</td>\n",
       "      <td>62867.5631</td>\n",
       "      <td>1.250500</td>\n",
       "      <td>0.342737</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Ithil_tobas_rodwen</td>\n",
       "      <td>62867.5631</td>\n",
       "      <td>1.298654</td>\n",
       "      <td>0.274093</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Ithil_tobas_rodwen</td>\n",
       "      <td>62864.6990</td>\n",
       "      <td>0.752622</td>\n",
       "      <td>0.080461</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>Ithil_tobas_rodwen</td>\n",
       "      <td>62864.6990</td>\n",
       "      <td>1.028319</td>\n",
       "      <td>0.199470</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>Ithil_tobas_rodwen</td>\n",
       "      <td>61807.8308</td>\n",
       "      <td>0.126247</td>\n",
       "      <td>0.247917</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>Ithil_tobas_rodwen</td>\n",
       "      <td>61810.6950</td>\n",
       "      <td>0.585870</td>\n",
       "      <td>0.314342</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>Ithil_tobas_rodwen</td>\n",
       "      <td>61799.2384</td>\n",
       "      <td>0.455831</td>\n",
       "      <td>0.175963</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>Ithil_tobas_rodwen</td>\n",
       "      <td>61807.8308</td>\n",
       "      <td>0.598166</td>\n",
       "      <td>0.606470</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>Ithil_tobas_rodwen</td>\n",
       "      <td>61810.6950</td>\n",
       "      <td>0.288758</td>\n",
       "      <td>0.374822</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>798 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               object_id  Time (MJD)      Flux  Flux_err Filter\n",
       "267   Ithil_tobas_rodwen  62867.5631  0.462736  1.159424      y\n",
       "268   Ithil_tobas_rodwen  62867.5631  1.250500  0.342737      z\n",
       "269   Ithil_tobas_rodwen  62867.5631  1.298654  0.274093      i\n",
       "270   Ithil_tobas_rodwen  62864.6990  0.752622  0.080461      g\n",
       "271   Ithil_tobas_rodwen  62864.6990  1.028319  0.199470      i\n",
       "...                  ...         ...       ...       ...    ...\n",
       "1060  Ithil_tobas_rodwen  61807.8308  0.126247  0.247917      z\n",
       "1061  Ithil_tobas_rodwen  61810.6950  0.585870  0.314342      i\n",
       "1062  Ithil_tobas_rodwen  61799.2384  0.455831  0.175963      i\n",
       "1063  Ithil_tobas_rodwen  61807.8308  0.598166  0.606470      y\n",
       "1064  Ithil_tobas_rodwen  61810.6950  0.288758  0.374822      g\n",
       "\n",
       "[798 rows x 5 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.iloc[3]\n",
    "split = x[\"split\"]\n",
    "obj_id = x[\"object_id\"]\n",
    "lc = get_lightcurve(split, obj_id)\n",
    "lc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4579990e",
   "metadata": {},
   "source": [
    "## Creating feature columns\n",
    "\n",
    "Each object has a time series (lightcurve) with observations in up to 6 filters: u, g, r, i, z, y\n",
    "\n",
    "The majority of these features were created by tasking AI to go through astronomy research papers and create features. I am not an astronomer therefore I cannot create astronomy features with my knowledge.\n",
    "\n",
    "- `Time (MJD)`: observation time in Modified Julian Date  \n",
    "- `Flux`: measured brightness (can be negative due to noise/subtraction artifacts)  \n",
    "- `Flux_err`: uncertainty in the flux measurement  \n",
    "- `Filter`: which band the observation belongs to  \n",
    "\n",
    "The goal of feature engineering here is to compress each irregular time series into a fixed-length numeric vector so a tabular model (like XGBoost) can learn patterns that separate classes.\n",
    "\n",
    "### 1) Global features (all filters combined)\n",
    "These are computed using all observations across all bands for a given object.  \n",
    "They summarize the overall time coverage, brightness distribution, variability, uncertainty, and signal quality.\n",
    "\n",
    "### 2) Per-filter features (computed separately per band)\n",
    "These are computed independently for each filter band.\n",
    "They let the model detect color-dependent behavior (for example: strong variability in `g` but not in `i`).\n",
    "\n",
    "## Global (all-filters combined) features\n",
    "\n",
    "Below are the global feature columns and what each one represents:\n",
    "\n",
    "| Feature | Meaning | Why it helps |\n",
    "|--------|---------|--------------|\n",
    "| `total_time` | Total time span covered by the object's observations: `(max(Time) - min(Time))` after shifting to start at zero | Separates fast events vs slow events and distinguishes sparse vs long-baseline coverage |\n",
    "| `n_obs` | Total number of observations across all filters | Captures sampling density and whether an object is well-measured |\n",
    "| `median_flux` | Median flux across all observations | Robust estimate of typical brightness (less sensitive to spikes) |\n",
    "| `mean_flux` | Mean flux across all observations | Captures average brightness but is more sensitive to outliers |\n",
    "| `std_flux` | Standard deviation of flux across all observations | Measures overall variability (high = more change over time) |\n",
    "| `min_flux` | Minimum observed flux | Captures dips, fading, or negative excursions from noise |\n",
    "| `max_flux` | Maximum observed flux | Captures peak brightness or flare intensity |\n",
    "| `range_flux` | Flux range: `max_flux - min_flux` | Simple variability amplitude proxy |\n",
    "| `median_err` | Median flux uncertainty across all observations | Measures how noisy the measurements are overall |\n",
    "| `median_snr` | Median signal-to-noise ratio: `median(\\|Flux\\| / Flux_err)` | Typical detection strength across observations |\n",
    "| `max_snr` | Maximum signal-to-noise ratio: `max(\\|Flux\\| / Flux_err)` | Whether the object ever has a highly confident detection |\n",
    "| `neg_flux_frac` | Fraction of observations where `Flux < 0` | Indicates low-SNR objects or subtraction-dominated measurements |\n",
    "\n",
    "## Per-filter (band-wise) features\n",
    "\n",
    "For each band in `filters = [\"u\", \"g\", \"r\", \"i\", \"z\", \"y\"]`, the following features are created:\n",
    "\n",
    "| Feature | Meaning | Why it helps |\n",
    "|--------|---------|--------------|\n",
    "| `n_obs_{band}` | Number of observations in this band | Some classes are observed more in specific bands; also captures missingness patterns |\n",
    "| `total_time_{band}` | Time span covered within this band | Band-dependent cadence coverage (important if data is uneven across filters) |\n",
    "| `median_flux_{band}` | Median flux in this band | Typical brightness in this band (captures spectral/color behavior) |\n",
    "| `std_flux_{band}` | Flux standard deviation in this band | Variability strength in that band |\n",
    "| `amp_{band}` | Simple amplitude proxy: `max(flux) - median(flux)` | Captures flare-like peaks or transient bursts without being too sensitive to one negative outlier |\n",
    "| `median_err_{band}` | Median uncertainty in this band | Band-specific noise level (some filters are noisier) |\n",
    "| `median_snr_{band}` | Median SNR in this band: `median(\\|flux\\| / err)` | Typical detection quality per filter |\n",
    "| `max_snr_{band}` | Max SNR in this band: `max(\\|flux\\| / err)` | Best detection strength per filter |\n",
    "| `neg_flux_frac_{band}` | Fraction of band observations with `flux < 0` | Band-specific low-SNR indicator |\n",
    "\n",
    "## Additional summary features\n",
    "\n",
    "These features describe how much band coverage exists overall:\n",
    "\n",
    "| Feature | Meaning | Why it helps |\n",
    "|--------|---------|--------------|\n",
    "| `n_filters_present` | Count of how many filters have at least 1 observation | Objects with multi-band coverage have richer information; missing bands may correlate with class |\n",
    "| `total_obs` | Total observations summed over all filters (same as `n_obs`) | Redundant but convenient for downstream logic or sanity checks |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17962ffc",
   "metadata": {},
   "source": [
    "Commenting is added by AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516dedf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = [\"u\", \"g\", \"r\", \"i\", \"z\", \"y\"]  # creating features for each filter\n",
    "\n",
    "# Global feature columns (computed using all observations combined)\n",
    "base_cols = [\n",
    "    \"total_time\",      # total time span covered by all observations\n",
    "    \"n_obs\",           # total number of observations across all filters\n",
    "    \"median_flux\",     # median flux across all observations\n",
    "    \"mean_flux\",       # mean flux across all observations\n",
    "    \"std_flux\",        # standard deviation of flux across all observations\n",
    "    \"min_flux\",        # minimum flux observed\n",
    "    \"max_flux\",        # maximum flux observed\n",
    "    \"range_flux\",      # max_flux - min_flux, variability range proxy\n",
    "    \"median_err\",      # median measurement uncertainty across all observations\n",
    "    \"median_snr\",      # median |flux| / err across all observations\n",
    "    \"max_snr\",         # maximum |flux| / err across all observations\n",
    "    \"neg_flux_frac\"    # fraction of observations with flux < 0\n",
    "]\n",
    "\n",
    "# Initialize global features to NaN (filled later per object)\n",
    "for c in base_cols:\n",
    "    df[c] = np.nan\n",
    "\n",
    "# Initialize per-filter features\n",
    "for f in filters:\n",
    "    df[f\"n_obs_{f}\"] = 0                  # number of observations in this band\n",
    "    df[f\"total_time_{f}\"] = 0.0           # time span covered in this band\n",
    "    df[f\"median_flux_{f}\"] = 0.0          # typical flux level in this band\n",
    "    df[f\"std_flux_{f}\"] = 0.0             # variability in this band\n",
    "    df[f\"amp_{f}\"] = 0.0                  # amplitude proxy in this band\n",
    "    df[f\"median_err_{f}\"] = 0.0           # typical uncertainty in this band\n",
    "    df[f\"median_snr_{f}\"] = 0.0           # typical SNR in this band\n",
    "    df[f\"max_snr_{f}\"] = 0.0              # best SNR in this band\n",
    "    df[f\"neg_flux_frac_{f}\"] = 0.0        # fraction of negative flux values in this band\n",
    "\n",
    "# Summary features for filter coverage\n",
    "df[\"n_filters_present\"] = 0               # how many bands have >= 1 observation\n",
    "df[\"total_obs\"] = 0                       # total observations across all bands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df855f3e",
   "metadata": {},
   "source": [
    "## Extracting features from the raw lightcurve (per object)\n",
    "\n",
    "This loop runs through every object in the dataframe and builds features from its lightcurve.\n",
    "\n",
    "### Steps per object\n",
    "1. Fetch the object's lightcurve with `get_lightcurve(split, object_id)`\n",
    "2. Extract arrays for:\n",
    "   - Time (MJD)\n",
    "   - Flux\n",
    "   - Flux_err\n",
    "3. Convert time into a relative scale (`t_rel = t - t.min()`)\n",
    "4. Compute global lightcurve stats:\n",
    "   - time span\n",
    "   - total observation count\n",
    "   - flux summary stats (median/mean/std/min/max/range)\n",
    "   - error and SNR summary stats\n",
    "   - fraction of negative flux values\n",
    "5. For each filter band (u,g,r,i,z,y):\n",
    "   - subset lightcurve rows for that band\n",
    "   - compute band-specific stats (n_obs, time span, median flux, std, amplitude, SNR, etc.)\n",
    "6. Track how many filters are actually present (`n_filters_present`)\n",
    "7. Track the total number of observations across all filters (`total_obs`)\n",
    "\n",
    "This produces a structured tabular feature dataset where each row corresponds to exactly one object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d590adfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(df.shape[0]):\n",
    "    x = df.iloc[i]\n",
    "    lc = get_lightcurve(x[\"split\"], x[\"object_id\"])\n",
    "\n",
    "    # Extract arrays for all observations (all filters combined)\n",
    "    t = lc[\"Time (MJD)\"].to_numpy()\n",
    "    f = lc[\"Flux\"].to_numpy()\n",
    "    e = lc[\"Flux_err\"].to_numpy()\n",
    "\n",
    "    # Shift time so the first observation occurs at t=0 for numerical stability\n",
    "    t_rel = t - t.min()\n",
    "\n",
    "    df.loc[i, \"total_time\"] = float(t_rel.max() - t_rel.min())  # overall time baseline\n",
    "    df.loc[i, \"n_obs\"] = int(lc.shape[0])                       # total number of observations\n",
    "\n",
    "    df.loc[i, \"median_flux\"] = float(np.median(f))              # typical brightness (robust)\n",
    "    df.loc[i, \"mean_flux\"]   = float(np.mean(f))                # average brightness\n",
    "    df.loc[i, \"std_flux\"]    = float(np.std(f))                 # overall variability\n",
    "    df.loc[i, \"min_flux\"]    = float(np.min(f))                 # dimmest point\n",
    "    df.loc[i, \"max_flux\"]    = float(np.max(f))                 # brightest point\n",
    "    df.loc[i, \"range_flux\"]  = float(np.max(f) - np.min(f))     # simple variability range\n",
    "\n",
    "    df.loc[i, \"median_err\"] = float(np.median(e))               # typical measurement noise\n",
    "    snr = np.abs(f) / (e + 1e-8)                                # SNR per observation\n",
    "    df.loc[i, \"median_snr\"] = float(np.median(snr))             # typical detection quality\n",
    "    df.loc[i, \"max_snr\"]    = float(np.max(snr))                # best detection quality\n",
    "    df.loc[i, \"neg_flux_frac\"] = float(np.mean(f < 0))          # how often flux is negative\n",
    "\n",
    "    present = 0\n",
    "    total_obs = 0\n",
    "\n",
    "    for band in filters:\n",
    "        sub = lc[lc[\"Filter\"] == band] # only observations in this band\n",
    "        n = int(sub.shape[0])\n",
    "\n",
    "        df.loc[i, f\"n_obs_{band}\"] = n\n",
    "        total_obs += n\n",
    "\n",
    "        # If the band is missing entirely, skip the rest\n",
    "        if n == 0:\n",
    "            continue\n",
    "        present += 1\n",
    "\n",
    "        tb = sub[\"Time (MJD)\"].to_numpy()\n",
    "        fb = sub[\"Flux\"].to_numpy()\n",
    "        eb = sub[\"Flux_err\"].to_numpy()\n",
    "\n",
    "        tb_rel = tb - tb.min()\n",
    "\n",
    "        # Band time span\n",
    "        df.loc[i, f\"total_time_{band}\"] = float(tb_rel.max() - tb_rel.min())\n",
    "\n",
    "        # Band flux distribution\n",
    "        df.loc[i, f\"median_flux_{band}\"] = float(np.median(fb))\n",
    "        df.loc[i, f\"std_flux_{band}\"] = float(np.std(fb))\n",
    "\n",
    "        # Band amplitude proxy (peak relative to median baseline)\n",
    "        df.loc[i, f\"amp_{band}\"] = float(np.max(fb) - np.median(fb))\n",
    "\n",
    "        # Band uncertainty + SNR\n",
    "        df.loc[i, f\"median_err_{band}\"] = float(np.median(eb))\n",
    "        snr_b = np.abs(fb) / (eb + 1e-8)\n",
    "        df.loc[i, f\"median_snr_{band}\"] = float(np.median(snr_b))\n",
    "        df.loc[i, f\"max_snr_{band}\"] = float(np.max(snr_b))\n",
    "\n",
    "        # Band negative flux fraction\n",
    "        df.loc[i, f\"neg_flux_frac_{band}\"] = float(np.mean(fb < 0))\n",
    "\n",
    "    # Final band coverage summaries\n",
    "    df.loc[i, \"n_filters_present\"] = int(present)\n",
    "    df.loc[i, \"total_obs\"] = int(total_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "628bd101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Z</th>\n",
       "      <th>EBV</th>\n",
       "      <th>total_time</th>\n",
       "      <th>n_obs</th>\n",
       "      <th>median_flux</th>\n",
       "      <th>mean_flux</th>\n",
       "      <th>std_flux</th>\n",
       "      <th>min_flux</th>\n",
       "      <th>max_flux</th>\n",
       "      <th>range_flux</th>\n",
       "      <th>...</th>\n",
       "      <th>total_time_y</th>\n",
       "      <th>median_flux_y</th>\n",
       "      <th>std_flux_y</th>\n",
       "      <th>amp_y</th>\n",
       "      <th>median_err_y</th>\n",
       "      <th>median_snr_y</th>\n",
       "      <th>max_snr_y</th>\n",
       "      <th>neg_flux_frac_y</th>\n",
       "      <th>n_filters_present</th>\n",
       "      <th>total_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0490</td>\n",
       "      <td>0.110</td>\n",
       "      <td>1254.2719</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-0.367840</td>\n",
       "      <td>0.928483</td>\n",
       "      <td>4.766352</td>\n",
       "      <td>-2.756285</td>\n",
       "      <td>25.047343</td>\n",
       "      <td>27.803628</td>\n",
       "      <td>...</td>\n",
       "      <td>1241.0691</td>\n",
       "      <td>-1.424537</td>\n",
       "      <td>2.463050</td>\n",
       "      <td>7.290787</td>\n",
       "      <td>1.111663</td>\n",
       "      <td>1.344504</td>\n",
       "      <td>3.762247</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>6</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4324</td>\n",
       "      <td>0.058</td>\n",
       "      <td>2362.1560</td>\n",
       "      <td>167.0</td>\n",
       "      <td>0.094237</td>\n",
       "      <td>0.388622</td>\n",
       "      <td>1.367368</td>\n",
       "      <td>-1.747082</td>\n",
       "      <td>11.375499</td>\n",
       "      <td>13.122581</td>\n",
       "      <td>...</td>\n",
       "      <td>2362.1560</td>\n",
       "      <td>0.094237</td>\n",
       "      <td>2.457391</td>\n",
       "      <td>11.281263</td>\n",
       "      <td>1.300994</td>\n",
       "      <td>0.576262</td>\n",
       "      <td>14.659265</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>6</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4673</td>\n",
       "      <td>0.577</td>\n",
       "      <td>1206.0218</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.076724</td>\n",
       "      <td>1.691347</td>\n",
       "      <td>2.602937</td>\n",
       "      <td>-6.400816</td>\n",
       "      <td>6.617915</td>\n",
       "      <td>13.018732</td>\n",
       "      <td>...</td>\n",
       "      <td>767.8628</td>\n",
       "      <td>0.032667</td>\n",
       "      <td>6.433483</td>\n",
       "      <td>6.433483</td>\n",
       "      <td>1.121800</td>\n",
       "      <td>5.735005</td>\n",
       "      <td>5.770355</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6946</td>\n",
       "      <td>0.012</td>\n",
       "      <td>2858.4129</td>\n",
       "      <td>798.0</td>\n",
       "      <td>0.327391</td>\n",
       "      <td>0.375366</td>\n",
       "      <td>0.859220</td>\n",
       "      <td>-7.641818</td>\n",
       "      <td>5.353821</td>\n",
       "      <td>12.995639</td>\n",
       "      <td>...</td>\n",
       "      <td>2841.2281</td>\n",
       "      <td>0.523353</td>\n",
       "      <td>1.798179</td>\n",
       "      <td>4.830468</td>\n",
       "      <td>1.079121</td>\n",
       "      <td>0.888426</td>\n",
       "      <td>3.630331</td>\n",
       "      <td>0.365217</td>\n",
       "      <td>6</td>\n",
       "      <td>798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4161</td>\n",
       "      <td>0.058</td>\n",
       "      <td>2202.3065</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.308845</td>\n",
       "      <td>0.233832</td>\n",
       "      <td>1.142101</td>\n",
       "      <td>-3.060399</td>\n",
       "      <td>5.384463</td>\n",
       "      <td>8.444862</td>\n",
       "      <td>...</td>\n",
       "      <td>1809.1164</td>\n",
       "      <td>0.826709</td>\n",
       "      <td>1.642351</td>\n",
       "      <td>1.543811</td>\n",
       "      <td>0.981047</td>\n",
       "      <td>1.312869</td>\n",
       "      <td>2.640597</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>6</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3038</th>\n",
       "      <td>0.8898</td>\n",
       "      <td>0.042</td>\n",
       "      <td>2582.0800</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.328642</td>\n",
       "      <td>0.459678</td>\n",
       "      <td>0.999605</td>\n",
       "      <td>-1.419681</td>\n",
       "      <td>6.428462</td>\n",
       "      <td>7.848143</td>\n",
       "      <td>...</td>\n",
       "      <td>2392.4960</td>\n",
       "      <td>0.758492</td>\n",
       "      <td>1.853276</td>\n",
       "      <td>5.669970</td>\n",
       "      <td>1.135060</td>\n",
       "      <td>0.997986</td>\n",
       "      <td>2.542929</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3039</th>\n",
       "      <td>0.9598</td>\n",
       "      <td>0.042</td>\n",
       "      <td>2916.1706</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.400943</td>\n",
       "      <td>0.374945</td>\n",
       "      <td>1.448300</td>\n",
       "      <td>-5.330229</td>\n",
       "      <td>7.369065</td>\n",
       "      <td>12.699294</td>\n",
       "      <td>...</td>\n",
       "      <td>2563.4588</td>\n",
       "      <td>0.363133</td>\n",
       "      <td>1.773719</td>\n",
       "      <td>2.076330</td>\n",
       "      <td>1.336029</td>\n",
       "      <td>0.498384</td>\n",
       "      <td>2.478262</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>6</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3040</th>\n",
       "      <td>0.1543</td>\n",
       "      <td>0.024</td>\n",
       "      <td>1936.1637</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.376307</td>\n",
       "      <td>1.070895</td>\n",
       "      <td>-2.773028</td>\n",
       "      <td>5.085714</td>\n",
       "      <td>7.858741</td>\n",
       "      <td>...</td>\n",
       "      <td>1919.4185</td>\n",
       "      <td>-0.031903</td>\n",
       "      <td>1.798593</td>\n",
       "      <td>5.117617</td>\n",
       "      <td>1.198319</td>\n",
       "      <td>0.698936</td>\n",
       "      <td>4.619904</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>6</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3041</th>\n",
       "      <td>1.1520</td>\n",
       "      <td>0.019</td>\n",
       "      <td>2699.8022</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.562826</td>\n",
       "      <td>0.352351</td>\n",
       "      <td>1.075207</td>\n",
       "      <td>-2.895248</td>\n",
       "      <td>2.871105</td>\n",
       "      <td>5.766353</td>\n",
       "      <td>...</td>\n",
       "      <td>2635.9214</td>\n",
       "      <td>0.300762</td>\n",
       "      <td>1.446578</td>\n",
       "      <td>2.512944</td>\n",
       "      <td>1.378667</td>\n",
       "      <td>0.673259</td>\n",
       "      <td>2.712396</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>6</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042</th>\n",
       "      <td>0.5595</td>\n",
       "      <td>0.034</td>\n",
       "      <td>1871.2077</td>\n",
       "      <td>167.0</td>\n",
       "      <td>-0.025445</td>\n",
       "      <td>0.275697</td>\n",
       "      <td>1.080632</td>\n",
       "      <td>-2.768392</td>\n",
       "      <td>4.432613</td>\n",
       "      <td>7.201005</td>\n",
       "      <td>...</td>\n",
       "      <td>1835.7234</td>\n",
       "      <td>0.372497</td>\n",
       "      <td>1.642016</td>\n",
       "      <td>4.060116</td>\n",
       "      <td>1.139062</td>\n",
       "      <td>0.934261</td>\n",
       "      <td>4.311639</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>6</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3043 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Z    EBV  total_time  n_obs  median_flux  mean_flux  std_flux  \\\n",
       "0     3.0490  0.110   1254.2719   65.0    -0.367840   0.928483  4.766352   \n",
       "1     0.4324  0.058   2362.1560  167.0     0.094237   0.388622  1.367368   \n",
       "2     0.4673  0.577   1206.0218   35.0     1.076724   1.691347  2.602937   \n",
       "3     0.6946  0.012   2858.4129  798.0     0.327391   0.375366  0.859220   \n",
       "4     0.4161  0.058   2202.3065  129.0     0.308845   0.233832  1.142101   \n",
       "...      ...    ...         ...    ...          ...        ...       ...   \n",
       "3038  0.8898  0.042   2582.0800  148.0     0.328642   0.459678  0.999605   \n",
       "3039  0.9598  0.042   2916.1706  138.0     0.400943   0.374945  1.448300   \n",
       "3040  0.1543  0.024   1936.1637  172.0     0.104000   0.376307  1.070895   \n",
       "3041  1.1520  0.019   2699.8022  161.0     0.562826   0.352351  1.075207   \n",
       "3042  0.5595  0.034   1871.2077  167.0    -0.025445   0.275697  1.080632   \n",
       "\n",
       "      min_flux   max_flux  range_flux  ...  total_time_y  median_flux_y  \\\n",
       "0    -2.756285  25.047343   27.803628  ...     1241.0691      -1.424537   \n",
       "1    -1.747082  11.375499   13.122581  ...     2362.1560       0.094237   \n",
       "2    -6.400816   6.617915   13.018732  ...      767.8628       0.032667   \n",
       "3    -7.641818   5.353821   12.995639  ...     2841.2281       0.523353   \n",
       "4    -3.060399   5.384463    8.444862  ...     1809.1164       0.826709   \n",
       "...        ...        ...         ...  ...           ...            ...   \n",
       "3038 -1.419681   6.428462    7.848143  ...     2392.4960       0.758492   \n",
       "3039 -5.330229   7.369065   12.699294  ...     2563.4588       0.363133   \n",
       "3040 -2.773028   5.085714    7.858741  ...     1919.4185      -0.031903   \n",
       "3041 -2.895248   2.871105    5.766353  ...     2635.9214       0.300762   \n",
       "3042 -2.768392   4.432613    7.201005  ...     1835.7234       0.372497   \n",
       "\n",
       "      std_flux_y      amp_y  median_err_y  median_snr_y  max_snr_y  \\\n",
       "0       2.463050   7.290787      1.111663      1.344504   3.762247   \n",
       "1       2.457391  11.281263      1.300994      0.576262  14.659265   \n",
       "2       6.433483   6.433483      1.121800      5.735005   5.770355   \n",
       "3       1.798179   4.830468      1.079121      0.888426   3.630331   \n",
       "4       1.642351   1.543811      0.981047      1.312869   2.640597   \n",
       "...          ...        ...           ...           ...        ...   \n",
       "3038    1.853276   5.669970      1.135060      0.997986   2.542929   \n",
       "3039    1.773719   2.076330      1.336029      0.498384   2.478262   \n",
       "3040    1.798593   5.117617      1.198319      0.698936   4.619904   \n",
       "3041    1.446578   2.512944      1.378667      0.673259   2.712396   \n",
       "3042    1.642016   4.060116      1.139062      0.934261   4.311639   \n",
       "\n",
       "      neg_flux_frac_y  n_filters_present  total_obs  \n",
       "0            0.545455                  6         65  \n",
       "1            0.482759                  6        167  \n",
       "2            0.500000                  6         35  \n",
       "3            0.365217                  6        798  \n",
       "4            0.285714                  6        129  \n",
       "...               ...                ...        ...  \n",
       "3038         0.375000                  6        148  \n",
       "3039         0.333333                  6        138  \n",
       "3040         0.548387                  6        172  \n",
       "3041         0.407407                  6        161  \n",
       "3042         0.433333                  6        167  \n",
       "\n",
       "[3043 rows x 70 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['target']\n",
    "X = df.drop(columns=['object_id', 'split', 'target'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eef8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4864e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(19.627118644067796)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg = (y_train == 0).sum()\n",
    "pos = (y_train == 1).sum()\n",
    "neg / pos # This dataset is heavily imbalanced, this ratio is for 'scale_pos_weight'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14c5d9a",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning using Optuna\n",
    "\n",
    "Use Optuna to search for XGBoost hyperparameters that maximize F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb4135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 300, 2000),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.2, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 8),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 20),\n",
    "\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.5, 1.0),\n",
    "\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
    "\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 10.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.1, 10.0),\n",
    "\n",
    "        \"scale_pos_weight\": 19.6,\n",
    "\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**params)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    probs = model.predict_proba(X_val)[:,1]\n",
    "\n",
    "    ths = np.linspace(0.01, 0.99, 200)\n",
    "    f1s = [f1_score(y_val, probs > t) for t in ths]\n",
    "\n",
    "    return float(np.max(f1s))\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=200)\n",
    "\n",
    "print(\"\\nBest F1:\", study.best_value)\n",
    "print(\"\\nBest params:\")\n",
    "for k, v in study.best_params.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b196d46d",
   "metadata": {},
   "source": [
    "Best F1: 0.7308\n",
    "\n",
    "## Results\n",
    "\n",
    "Best parameters:\n",
    "- n_estimators: 1556\n",
    "- learning_rate: 0.011529\n",
    "- max_depth: 5\n",
    "- min_child_weight: 11\n",
    "- subsample: 0.990469\n",
    "- colsample_bytree: 0.964860\n",
    "- colsample_bylevel: 0.931161\n",
    "- gamma: 0.008020\n",
    "- reg_alpha: 7.434848\n",
    "- reg_lambda: 1.937161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "95f3ef70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.5147491638795987\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "\n",
    "model = XGBClassifier(\n",
    "    **best_params,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    scale_pos_weight=19.6,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "probs = model.predict_proba(X_val)[:,1]\n",
    "\n",
    "ths = np.linspace(0.01, 0.99, 300)\n",
    "f1s = [f1_score(y_val, probs > t) for t in ths]\n",
    "best_t = ths[np.argmax(f1s)]\n",
    "\n",
    "print(\"Best threshold:\", best_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f19a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader.test_loader import build_test\n",
    "\n",
    "X_test, test_df = build_test()\n",
    "probs = model.predict_proba(X_test)[:,1]\n",
    "y_test_pred = (probs > best_t).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"object_id\": test_df[\"object_id\"],\n",
    "    \"target\": y_test_pred\n",
    "})\n",
    "submission.to_csv(\"Submissions/first_XGB-2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
